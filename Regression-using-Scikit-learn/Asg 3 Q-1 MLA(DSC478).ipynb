{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>Lincolntown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Selmacity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.55</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>Hendersoncity</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.53</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>Claytoncity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "5      6    SouthPasadenacity        0.02           0.28          0.06   \n",
       "6     44          Lincolntown        0.01           0.39          0.00   \n",
       "7      6            Selmacity        0.01           0.74          0.03   \n",
       "8     21        Hendersoncity        0.03           0.34          0.20   \n",
       "9     29          Claytoncity        0.01           0.40          0.06   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  ...  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47  ...   \n",
       "1          0.74          0.45         0.07         0.26         0.59  ...   \n",
       "2          0.56          0.17         0.04         0.39         0.47  ...   \n",
       "3          0.08          0.12         0.10         0.51         0.50  ...   \n",
       "4          0.95          0.09         0.05         0.38         0.38  ...   \n",
       "5          0.54          1.00         0.25         0.31         0.48  ...   \n",
       "6          0.98          0.06         0.02         0.30         0.37  ...   \n",
       "7          0.46          0.20         1.00         0.52         0.55  ...   \n",
       "8          0.84          0.02         0.00         0.38         0.45  ...   \n",
       "9          0.87          0.30         0.03         0.90         0.82  ...   \n",
       "\n",
       "   NumStreet  PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0        0.0            0.12              0.42            0.50           0.51   \n",
       "1        0.0            0.21              0.50            0.34           0.60   \n",
       "2        0.0            0.14              0.49            0.54           0.67   \n",
       "3        0.0            0.19              0.30            0.73           0.64   \n",
       "4        0.0            0.11              0.72            0.64           0.61   \n",
       "5        0.0            0.70              0.42            0.49           0.73   \n",
       "6        0.0            0.15              0.81            0.77           0.91   \n",
       "7        0.0            0.59              0.58            0.52           0.79   \n",
       "8        0.0            0.01              0.78            0.48           0.79   \n",
       "9        0.0            0.22              0.42            0.34           0.23   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "0            0.64      0.12     0.26            0.20                 0.20  \n",
       "1            0.52      0.02     0.12            0.45                 0.67  \n",
       "2            0.56      0.01     0.21            0.02                 0.43  \n",
       "3            0.65      0.02     0.39            0.28                 0.12  \n",
       "4            0.53      0.04     0.09            0.02                 0.03  \n",
       "5            0.64      0.01     0.58            0.10                 0.14  \n",
       "6            0.84      0.05     0.08            0.06                 0.03  \n",
       "7            0.78      0.01     0.33            0.00                 0.55  \n",
       "8            0.75      0.04     0.17            0.04                 0.53  \n",
       "9            0.09      0.00     0.47            0.11                 0.15  \n",
       "\n",
       "[10 rows x 100 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "communities = pd.read_csv(r'C:\\Users\\MDESAI12\\Downloads\\communities\\communities.csv')\n",
    "communities.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "state                    0\n",
       "communityname            0\n",
       "population               0\n",
       "householdsize            0\n",
       "racepctblack             0\n",
       "racePctWhite             0\n",
       "racePctAsian             0\n",
       "racePctHisp              0\n",
       "agePct12t21              0\n",
       "agePct12t29              0\n",
       "agePct16t24              0\n",
       "agePct65up               0\n",
       "numbUrban                0\n",
       "pctUrban                 0\n",
       "medIncome                0\n",
       "pctWWage                 0\n",
       "pctWFarmSelf             0\n",
       "pctWInvInc               0\n",
       "pctWSocSec               0\n",
       "pctWPubAsst              0\n",
       "pctWRetire               0\n",
       "medFamInc                0\n",
       "perCapInc                0\n",
       "whitePerCap              0\n",
       "blackPerCap              0\n",
       "indianPerCap             0\n",
       "AsianPerCap              0\n",
       "OtherPerCap              1\n",
       "HispPerCap               0\n",
       "NumUnderPov              0\n",
       "                        ..\n",
       "MedNumBR                 0\n",
       "HousVacant               0\n",
       "PctHousOccup             0\n",
       "PctHousOwnOcc            0\n",
       "PctVacantBoarded         0\n",
       "PctVacMore6Mos           0\n",
       "MedYrHousBuilt           0\n",
       "PctHousNoPhone           0\n",
       "PctWOFullPlumb           0\n",
       "OwnOccLowQuart           0\n",
       "OwnOccMedVal             0\n",
       "OwnOccHiQuart            0\n",
       "RentLowQ                 0\n",
       "RentMedian               0\n",
       "RentHighQ                0\n",
       "MedRent                  0\n",
       "MedRentPctHousInc        0\n",
       "MedOwnCostPctInc         0\n",
       "MedOwnCostPctIncNoMtg    0\n",
       "NumInShelters            0\n",
       "NumStreet                0\n",
       "PctForeignBorn           0\n",
       "PctBornSameState         0\n",
       "PctSameHouse85           0\n",
       "PctSameCity85            0\n",
       "PctSameState85           0\n",
       "LandArea                 0\n",
       "PopDens                  0\n",
       "PctUsePubTrans           0\n",
       "ViolentCrimesPerPop      0\n",
       "Length: 100, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities = communities.replace(\"?\", np.NaN)\n",
    "communities.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacksonvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state     communityname   population  householdsize  \\\n",
       "count   1994.000000              1994  1994.000000    1994.000000   \n",
       "unique          NaN              1828          NaN            NaN   \n",
       "top             NaN  Jacksonvillecity          NaN            NaN   \n",
       "freq            NaN                 5          NaN            NaN   \n",
       "mean      28.683551               NaN     0.057593       0.463395   \n",
       "std       16.397553               NaN     0.126906       0.163717   \n",
       "min        1.000000               NaN     0.000000       0.000000   \n",
       "25%       12.000000               NaN     0.010000       0.350000   \n",
       "50%       34.000000               NaN     0.020000       0.440000   \n",
       "75%       42.000000               NaN     0.050000       0.540000   \n",
       "max       56.000000               NaN     1.000000       1.000000   \n",
       "\n",
       "        racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  \\\n",
       "count    1994.000000   1994.000000   1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN           NaN          NaN          NaN   \n",
       "top              NaN           NaN           NaN          NaN          NaN   \n",
       "freq             NaN           NaN           NaN          NaN          NaN   \n",
       "mean        0.179629      0.753716      0.153681     0.144022     0.424218   \n",
       "std         0.253442      0.244039      0.208877     0.232492     0.155196   \n",
       "min         0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%         0.020000      0.630000      0.040000     0.010000     0.340000   \n",
       "50%         0.060000      0.850000      0.070000     0.040000     0.400000   \n",
       "75%         0.230000      0.940000      0.170000     0.160000     0.470000   \n",
       "max         1.000000      1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "        agePct12t29  ...    NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "count   1994.000000  ...  1994.000000     1994.000000       1994.000000   \n",
       "unique          NaN  ...          NaN             NaN               NaN   \n",
       "top             NaN  ...          NaN             NaN               NaN   \n",
       "freq            NaN  ...          NaN             NaN               NaN   \n",
       "mean       0.493867  ...     0.022778        0.215552          0.608892   \n",
       "std        0.143564  ...     0.100400        0.231134          0.204329   \n",
       "min        0.000000  ...     0.000000        0.000000          0.000000   \n",
       "25%        0.410000  ...     0.000000        0.060000          0.470000   \n",
       "50%        0.480000  ...     0.000000        0.130000          0.630000   \n",
       "75%        0.540000  ...     0.000000        0.280000          0.777500   \n",
       "max        1.000000  ...     1.000000        1.000000          1.000000   \n",
       "\n",
       "        PctSameHouse85  PctSameCity85  PctSameState85     LandArea  \\\n",
       "count      1994.000000    1994.000000     1994.000000  1994.000000   \n",
       "unique             NaN            NaN             NaN          NaN   \n",
       "top                NaN            NaN             NaN          NaN   \n",
       "freq               NaN            NaN             NaN          NaN   \n",
       "mean          0.535050       0.626424        0.651530     0.065231   \n",
       "std           0.181352       0.200521        0.198221     0.109459   \n",
       "min           0.000000       0.000000        0.000000     0.000000   \n",
       "25%           0.420000       0.520000        0.560000     0.020000   \n",
       "50%           0.540000       0.670000        0.700000     0.040000   \n",
       "75%           0.660000       0.770000        0.790000     0.070000   \n",
       "max           1.000000       1.000000        1.000000     1.000000   \n",
       "\n",
       "            PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN             NaN                  NaN  \n",
       "top             NaN             NaN                  NaN  \n",
       "freq            NaN             NaN                  NaN  \n",
       "mean       0.232854        0.161685             0.237979  \n",
       "std        0.203092        0.229055             0.232985  \n",
       "min        0.000000        0.000000             0.000000  \n",
       "25%        0.100000        0.020000             0.070000  \n",
       "50%        0.170000        0.070000             0.150000  \n",
       "75%        0.280000        0.190000             0.330000  \n",
       "max        1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities['OtherPerCap'] = pd.to_numeric(communities['OtherPerCap'])\n",
    "mean = communities.OtherPerCap.mean()\n",
    "communities.OtherPerCap.fillna(mean, axis=0, inplace = True)\n",
    "communities.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "      <th>ViolentCrimesPerPop</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "      <td>1994.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>1828</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>Jacksonvillecity</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>28.683551</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.057593</td>\n",
       "      <td>0.463395</td>\n",
       "      <td>0.179629</td>\n",
       "      <td>0.753716</td>\n",
       "      <td>0.153681</td>\n",
       "      <td>0.144022</td>\n",
       "      <td>0.424218</td>\n",
       "      <td>0.493867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.022778</td>\n",
       "      <td>0.215552</td>\n",
       "      <td>0.608892</td>\n",
       "      <td>0.535050</td>\n",
       "      <td>0.626424</td>\n",
       "      <td>0.651530</td>\n",
       "      <td>0.065231</td>\n",
       "      <td>0.232854</td>\n",
       "      <td>0.161685</td>\n",
       "      <td>0.237979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>16.397553</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.126906</td>\n",
       "      <td>0.163717</td>\n",
       "      <td>0.253442</td>\n",
       "      <td>0.244039</td>\n",
       "      <td>0.208877</td>\n",
       "      <td>0.232492</td>\n",
       "      <td>0.155196</td>\n",
       "      <td>0.143564</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100400</td>\n",
       "      <td>0.231134</td>\n",
       "      <td>0.204329</td>\n",
       "      <td>0.181352</td>\n",
       "      <td>0.200521</td>\n",
       "      <td>0.198221</td>\n",
       "      <td>0.109459</td>\n",
       "      <td>0.203092</td>\n",
       "      <td>0.229055</td>\n",
       "      <td>0.232985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>12.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.350000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.340000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.420000</td>\n",
       "      <td>0.520000</td>\n",
       "      <td>0.560000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.070000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>34.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.440000</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.850000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.130000</td>\n",
       "      <td>0.630000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.670000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.150000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>42.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.050000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.940000</td>\n",
       "      <td>0.170000</td>\n",
       "      <td>0.160000</td>\n",
       "      <td>0.470000</td>\n",
       "      <td>0.540000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.777500</td>\n",
       "      <td>0.660000</td>\n",
       "      <td>0.770000</td>\n",
       "      <td>0.790000</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.280000</td>\n",
       "      <td>0.190000</td>\n",
       "      <td>0.330000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>56.000000</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 100 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              state     communityname   population  householdsize  \\\n",
       "count   1994.000000              1994  1994.000000    1994.000000   \n",
       "unique          NaN              1828          NaN            NaN   \n",
       "top             NaN  Jacksonvillecity          NaN            NaN   \n",
       "freq            NaN                 5          NaN            NaN   \n",
       "mean      28.683551               NaN     0.057593       0.463395   \n",
       "std       16.397553               NaN     0.126906       0.163717   \n",
       "min        1.000000               NaN     0.000000       0.000000   \n",
       "25%       12.000000               NaN     0.010000       0.350000   \n",
       "50%       34.000000               NaN     0.020000       0.440000   \n",
       "75%       42.000000               NaN     0.050000       0.540000   \n",
       "max       56.000000               NaN     1.000000       1.000000   \n",
       "\n",
       "        racepctblack  racePctWhite  racePctAsian  racePctHisp  agePct12t21  \\\n",
       "count    1994.000000   1994.000000   1994.000000  1994.000000  1994.000000   \n",
       "unique           NaN           NaN           NaN          NaN          NaN   \n",
       "top              NaN           NaN           NaN          NaN          NaN   \n",
       "freq             NaN           NaN           NaN          NaN          NaN   \n",
       "mean        0.179629      0.753716      0.153681     0.144022     0.424218   \n",
       "std         0.253442      0.244039      0.208877     0.232492     0.155196   \n",
       "min         0.000000      0.000000      0.000000     0.000000     0.000000   \n",
       "25%         0.020000      0.630000      0.040000     0.010000     0.340000   \n",
       "50%         0.060000      0.850000      0.070000     0.040000     0.400000   \n",
       "75%         0.230000      0.940000      0.170000     0.160000     0.470000   \n",
       "max         1.000000      1.000000      1.000000     1.000000     1.000000   \n",
       "\n",
       "        agePct12t29  ...    NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "count   1994.000000  ...  1994.000000     1994.000000       1994.000000   \n",
       "unique          NaN  ...          NaN             NaN               NaN   \n",
       "top             NaN  ...          NaN             NaN               NaN   \n",
       "freq            NaN  ...          NaN             NaN               NaN   \n",
       "mean       0.493867  ...     0.022778        0.215552          0.608892   \n",
       "std        0.143564  ...     0.100400        0.231134          0.204329   \n",
       "min        0.000000  ...     0.000000        0.000000          0.000000   \n",
       "25%        0.410000  ...     0.000000        0.060000          0.470000   \n",
       "50%        0.480000  ...     0.000000        0.130000          0.630000   \n",
       "75%        0.540000  ...     0.000000        0.280000          0.777500   \n",
       "max        1.000000  ...     1.000000        1.000000          1.000000   \n",
       "\n",
       "        PctSameHouse85  PctSameCity85  PctSameState85     LandArea  \\\n",
       "count      1994.000000    1994.000000     1994.000000  1994.000000   \n",
       "unique             NaN            NaN             NaN          NaN   \n",
       "top                NaN            NaN             NaN          NaN   \n",
       "freq               NaN            NaN             NaN          NaN   \n",
       "mean          0.535050       0.626424        0.651530     0.065231   \n",
       "std           0.181352       0.200521        0.198221     0.109459   \n",
       "min           0.000000       0.000000        0.000000     0.000000   \n",
       "25%           0.420000       0.520000        0.560000     0.020000   \n",
       "50%           0.540000       0.670000        0.700000     0.040000   \n",
       "75%           0.660000       0.770000        0.790000     0.070000   \n",
       "max           1.000000       1.000000        1.000000     1.000000   \n",
       "\n",
       "            PopDens  PctUsePubTrans  ViolentCrimesPerPop  \n",
       "count   1994.000000     1994.000000          1994.000000  \n",
       "unique          NaN             NaN                  NaN  \n",
       "top             NaN             NaN                  NaN  \n",
       "freq            NaN             NaN                  NaN  \n",
       "mean       0.232854        0.161685             0.237979  \n",
       "std        0.203092        0.229055             0.232985  \n",
       "min        0.000000        0.000000             0.000000  \n",
       "25%        0.100000        0.020000             0.070000  \n",
       "50%        0.170000        0.070000             0.150000  \n",
       "75%        0.280000        0.190000             0.330000  \n",
       "max        1.000000        1.000000             1.000000  \n",
       "\n",
       "[11 rows x 100 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.20\n",
       "1    0.67\n",
       "2    0.43\n",
       "3    0.12\n",
       "4    0.03\n",
       "5    0.14\n",
       "6    0.03\n",
       "7    0.55\n",
       "8    0.53\n",
       "9    0.15\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_target = communities['ViolentCrimesPerPop']\n",
    "communities_target.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>communityname</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>Lakewoodcity</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>Tukwilacity</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>Aberdeentown</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>Willingborotownship</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>Bethlehemtownship</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>SouthPasadenacity</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>Lincolntown</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>Selmacity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>Hendersoncity</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>Claytoncity</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 99 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state        communityname  population  householdsize  racepctblack  \\\n",
       "0      8         Lakewoodcity        0.19           0.33          0.02   \n",
       "1     53          Tukwilacity        0.00           0.16          0.12   \n",
       "2     24         Aberdeentown        0.00           0.42          0.49   \n",
       "3     34  Willingborotownship        0.04           0.77          1.00   \n",
       "4     42    Bethlehemtownship        0.01           0.55          0.02   \n",
       "5      6    SouthPasadenacity        0.02           0.28          0.06   \n",
       "6     44          Lincolntown        0.01           0.39          0.00   \n",
       "7      6            Selmacity        0.01           0.74          0.03   \n",
       "8     21        Hendersoncity        0.03           0.34          0.20   \n",
       "9     29          Claytoncity        0.01           0.40          0.06   \n",
       "\n",
       "   racePctWhite  racePctAsian  racePctHisp  agePct12t21  agePct12t29  ...  \\\n",
       "0          0.90          0.12         0.17         0.34         0.47  ...   \n",
       "1          0.74          0.45         0.07         0.26         0.59  ...   \n",
       "2          0.56          0.17         0.04         0.39         0.47  ...   \n",
       "3          0.08          0.12         0.10         0.51         0.50  ...   \n",
       "4          0.95          0.09         0.05         0.38         0.38  ...   \n",
       "5          0.54          1.00         0.25         0.31         0.48  ...   \n",
       "6          0.98          0.06         0.02         0.30         0.37  ...   \n",
       "7          0.46          0.20         1.00         0.52         0.55  ...   \n",
       "8          0.84          0.02         0.00         0.38         0.45  ...   \n",
       "9          0.87          0.30         0.03         0.90         0.82  ...   \n",
       "\n",
       "   NumInShelters  NumStreet  PctForeignBorn  PctBornSameState  PctSameHouse85  \\\n",
       "0           0.04        0.0            0.12              0.42            0.50   \n",
       "1           0.00        0.0            0.21              0.50            0.34   \n",
       "2           0.00        0.0            0.14              0.49            0.54   \n",
       "3           0.00        0.0            0.19              0.30            0.73   \n",
       "4           0.00        0.0            0.11              0.72            0.64   \n",
       "5           0.00        0.0            0.70              0.42            0.49   \n",
       "6           0.00        0.0            0.15              0.81            0.77   \n",
       "7           0.00        0.0            0.59              0.58            0.52   \n",
       "8           0.01        0.0            0.01              0.78            0.48   \n",
       "9           0.00        0.0            0.22              0.42            0.34   \n",
       "\n",
       "   PctSameCity85  PctSameState85  LandArea  PopDens  PctUsePubTrans  \n",
       "0           0.51            0.64      0.12     0.26            0.20  \n",
       "1           0.60            0.52      0.02     0.12            0.45  \n",
       "2           0.67            0.56      0.01     0.21            0.02  \n",
       "3           0.64            0.65      0.02     0.39            0.28  \n",
       "4           0.61            0.53      0.04     0.09            0.02  \n",
       "5           0.73            0.64      0.01     0.58            0.10  \n",
       "6           0.91            0.84      0.05     0.08            0.06  \n",
       "7           0.79            0.78      0.01     0.33            0.00  \n",
       "8           0.79            0.75      0.04     0.17            0.04  \n",
       "9           0.23            0.09      0.00     0.47            0.11  \n",
       "\n",
       "[10 rows x 99 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_1 = communities.drop('ViolentCrimesPerPop', axis=1)\n",
    "communities_1.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>53</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.45</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>24</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>34</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.54</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.27</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>44</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.98</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.77</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>6</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.20</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>21</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>29</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.80</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   state  population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0      8        0.19           0.33          0.02          0.90          0.12   \n",
       "1     53        0.00           0.16          0.12          0.74          0.45   \n",
       "2     24        0.00           0.42          0.49          0.56          0.17   \n",
       "3     34        0.04           0.77          1.00          0.08          0.12   \n",
       "4     42        0.01           0.55          0.02          0.95          0.09   \n",
       "5      6        0.02           0.28          0.06          0.54          1.00   \n",
       "6     44        0.01           0.39          0.00          0.98          0.06   \n",
       "7      6        0.01           0.74          0.03          0.46          0.20   \n",
       "8     21        0.03           0.34          0.20          0.84          0.02   \n",
       "9     29        0.01           0.40          0.06          0.87          0.30   \n",
       "\n",
       "   racePctHisp  agePct12t21  agePct12t29  agePct16t24  ...  NumInShelters  \\\n",
       "0         0.17         0.34         0.47         0.29  ...           0.04   \n",
       "1         0.07         0.26         0.59         0.35  ...           0.00   \n",
       "2         0.04         0.39         0.47         0.28  ...           0.00   \n",
       "3         0.10         0.51         0.50         0.34  ...           0.00   \n",
       "4         0.05         0.38         0.38         0.23  ...           0.00   \n",
       "5         0.25         0.31         0.48         0.27  ...           0.00   \n",
       "6         0.02         0.30         0.37         0.23  ...           0.00   \n",
       "7         1.00         0.52         0.55         0.36  ...           0.00   \n",
       "8         0.00         0.38         0.45         0.28  ...           0.01   \n",
       "9         0.03         0.90         0.82         0.80  ...           0.00   \n",
       "\n",
       "   NumStreet  PctForeignBorn  PctBornSameState  PctSameHouse85  PctSameCity85  \\\n",
       "0        0.0            0.12              0.42            0.50           0.51   \n",
       "1        0.0            0.21              0.50            0.34           0.60   \n",
       "2        0.0            0.14              0.49            0.54           0.67   \n",
       "3        0.0            0.19              0.30            0.73           0.64   \n",
       "4        0.0            0.11              0.72            0.64           0.61   \n",
       "5        0.0            0.70              0.42            0.49           0.73   \n",
       "6        0.0            0.15              0.81            0.77           0.91   \n",
       "7        0.0            0.59              0.58            0.52           0.79   \n",
       "8        0.0            0.01              0.78            0.48           0.79   \n",
       "9        0.0            0.22              0.42            0.34           0.23   \n",
       "\n",
       "   PctSameState85  LandArea  PopDens  PctUsePubTrans  \n",
       "0            0.64      0.12     0.26            0.20  \n",
       "1            0.52      0.02     0.12            0.45  \n",
       "2            0.56      0.01     0.21            0.02  \n",
       "3            0.65      0.02     0.39            0.28  \n",
       "4            0.53      0.04     0.09            0.02  \n",
       "5            0.64      0.01     0.58            0.10  \n",
       "6            0.84      0.05     0.08            0.06  \n",
       "7            0.78      0.01     0.33            0.00  \n",
       "8            0.75      0.04     0.17            0.04  \n",
       "9            0.09      0.00     0.47            0.11  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_1 = communities_1.drop('communityname', axis=1)\n",
    "communities_1.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting data into 80/20 training,testing respectivly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(399, 98)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  population  householdsize  racepctblack  racePctWhite  \\\n",
       "1158      4        0.00           0.46          0.01          0.97   \n",
       "1079     25        0.01           0.35          0.01          0.96   \n",
       "1633     36        0.51           0.31          0.60          0.46   \n",
       "1700     48        0.02           0.52          0.25          0.63   \n",
       "1956     37        0.03           0.37          0.40          0.68   \n",
       "1808     29        0.05           0.32          0.94          0.22   \n",
       "136      25        0.00           0.53          0.02          0.96   \n",
       "46       34        0.03           0.67          0.45          0.61   \n",
       "1989     12        0.01           0.40          0.10          0.87   \n",
       "4        42        0.01           0.55          0.02          0.95   \n",
       "\n",
       "      racePctAsian  racePctHisp  agePct12t21  agePct12t29  agePct16t24  ...  \\\n",
       "1158          0.09         0.04         0.40         0.26         0.20  ...   \n",
       "1079          0.04         0.04         0.32         0.45         0.29  ...   \n",
       "1633          0.06         0.09         0.42         0.54         0.39  ...   \n",
       "1700          0.03         0.31         0.54         0.62         0.44  ...   \n",
       "1956          0.03         0.01         0.39         0.47         0.34  ...   \n",
       "1808          0.13         0.02         0.37         0.47         0.31  ...   \n",
       "136           0.08         0.01         0.38         0.31         0.22  ...   \n",
       "46            0.07         0.05         0.38         0.50         0.25  ...   \n",
       "1989          0.12         0.16         0.43         0.51         0.35  ...   \n",
       "4             0.09         0.05         0.38         0.38         0.23  ...   \n",
       "\n",
       "      NumInShelters  NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "1158           0.00       0.00            0.18              0.13   \n",
       "1079           0.00       0.00            0.11              0.86   \n",
       "1633           0.17       0.01            0.13              0.80   \n",
       "1700           0.01       0.00            0.13              0.72   \n",
       "1956           0.01       0.01            0.03              0.78   \n",
       "1808           0.01       0.00            0.18              0.60   \n",
       "136            0.00       0.00            0.15              0.68   \n",
       "46             0.07       0.00            0.07              0.51   \n",
       "1989           0.00       0.00            0.22              0.28   \n",
       "4              0.00       0.00            0.11              0.72   \n",
       "\n",
       "      PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "1158            0.73           0.76            0.55      0.04     0.06   \n",
       "1079            0.66           0.88            0.80      0.03     0.11   \n",
       "1633            0.61           0.87            0.84      0.12     0.68   \n",
       "1700            0.35           0.50            0.70      0.13     0.04   \n",
       "1956            0.59           0.71            0.69      0.06     0.10   \n",
       "1808            0.65           0.54            0.66      0.01     0.57   \n",
       "136             0.85           0.85            0.75      0.06     0.05   \n",
       "46              0.58           0.57            0.66      0.17     0.04   \n",
       "1989            0.34           0.48            0.39      0.01     0.28   \n",
       "4               0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "      PctUsePubTrans  \n",
       "1158            0.03  \n",
       "1079            0.01  \n",
       "1633            0.75  \n",
       "1700            0.01  \n",
       "1956            0.00  \n",
       "1808            0.27  \n",
       "136             0.07  \n",
       "46              0.34  \n",
       "1989            0.05  \n",
       "4               0.02  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "communities_train, communities_test, communities_target_train, communities_target_test = train_test_split(communities_1, communities_target, test_size=0.2, random_state=33)\n",
    "print(communities_test.shape)\n",
    "communities_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "communities_train_f = communities_train\n",
    "communities_test_f = communities_test\n",
    "communities_target_train_f = communities_target_train\n",
    "communities_target_test_f = communities_target_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1158</th>\n",
       "      <td>4</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.20</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>25</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.29</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1633</th>\n",
       "      <td>36</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.46</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.39</td>\n",
       "      <td>...</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1700</th>\n",
       "      <td>48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.63</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.44</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>37</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.34</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.78</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1808</th>\n",
       "      <td>29</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.94</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>25</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.96</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.31</td>\n",
       "      <td>0.22</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.06</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>34</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>12</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.40</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.87</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.43</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.35</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.39</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>42</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.23</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.02</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  population  householdsize  racepctblack  racePctWhite  \\\n",
       "1158      4        0.00           0.46          0.01          0.97   \n",
       "1079     25        0.01           0.35          0.01          0.96   \n",
       "1633     36        0.51           0.31          0.60          0.46   \n",
       "1700     48        0.02           0.52          0.25          0.63   \n",
       "1956     37        0.03           0.37          0.40          0.68   \n",
       "1808     29        0.05           0.32          0.94          0.22   \n",
       "136      25        0.00           0.53          0.02          0.96   \n",
       "46       34        0.03           0.67          0.45          0.61   \n",
       "1989     12        0.01           0.40          0.10          0.87   \n",
       "4        42        0.01           0.55          0.02          0.95   \n",
       "\n",
       "      racePctAsian  racePctHisp  agePct12t21  agePct12t29  agePct16t24  ...  \\\n",
       "1158          0.09         0.04         0.40         0.26         0.20  ...   \n",
       "1079          0.04         0.04         0.32         0.45         0.29  ...   \n",
       "1633          0.06         0.09         0.42         0.54         0.39  ...   \n",
       "1700          0.03         0.31         0.54         0.62         0.44  ...   \n",
       "1956          0.03         0.01         0.39         0.47         0.34  ...   \n",
       "1808          0.13         0.02         0.37         0.47         0.31  ...   \n",
       "136           0.08         0.01         0.38         0.31         0.22  ...   \n",
       "46            0.07         0.05         0.38         0.50         0.25  ...   \n",
       "1989          0.12         0.16         0.43         0.51         0.35  ...   \n",
       "4             0.09         0.05         0.38         0.38         0.23  ...   \n",
       "\n",
       "      NumInShelters  NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "1158           0.00       0.00            0.18              0.13   \n",
       "1079           0.00       0.00            0.11              0.86   \n",
       "1633           0.17       0.01            0.13              0.80   \n",
       "1700           0.01       0.00            0.13              0.72   \n",
       "1956           0.01       0.01            0.03              0.78   \n",
       "1808           0.01       0.00            0.18              0.60   \n",
       "136            0.00       0.00            0.15              0.68   \n",
       "46             0.07       0.00            0.07              0.51   \n",
       "1989           0.00       0.00            0.22              0.28   \n",
       "4              0.00       0.00            0.11              0.72   \n",
       "\n",
       "      PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "1158            0.73           0.76            0.55      0.04     0.06   \n",
       "1079            0.66           0.88            0.80      0.03     0.11   \n",
       "1633            0.61           0.87            0.84      0.12     0.68   \n",
       "1700            0.35           0.50            0.70      0.13     0.04   \n",
       "1956            0.59           0.71            0.69      0.06     0.10   \n",
       "1808            0.65           0.54            0.66      0.01     0.57   \n",
       "136             0.85           0.85            0.75      0.06     0.05   \n",
       "46              0.58           0.57            0.66      0.17     0.04   \n",
       "1989            0.34           0.48            0.39      0.01     0.28   \n",
       "4               0.64           0.61            0.53      0.04     0.09   \n",
       "\n",
       "      PctUsePubTrans  \n",
       "1158            0.03  \n",
       "1079            0.01  \n",
       "1633            0.75  \n",
       "1700            0.01  \n",
       "1956            0.00  \n",
       "1808            0.27  \n",
       "136             0.07  \n",
       "46              0.34  \n",
       "1989            0.05  \n",
       "4               0.02  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>state</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>agePct12t21</th>\n",
       "      <th>agePct12t29</th>\n",
       "      <th>agePct16t24</th>\n",
       "      <th>...</th>\n",
       "      <th>NumInShelters</th>\n",
       "      <th>NumStreet</th>\n",
       "      <th>PctForeignBorn</th>\n",
       "      <th>PctBornSameState</th>\n",
       "      <th>PctSameHouse85</th>\n",
       "      <th>PctSameCity85</th>\n",
       "      <th>PctSameState85</th>\n",
       "      <th>LandArea</th>\n",
       "      <th>PopDens</th>\n",
       "      <th>PctUsePubTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1184</th>\n",
       "      <td>34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.91</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.25</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.47</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>401</th>\n",
       "      <td>55</td>\n",
       "      <td>0.99</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.59</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.37</td>\n",
       "      <td>...</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.79</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>34</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.18</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1390</th>\n",
       "      <td>25</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.97</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.31</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1066</th>\n",
       "      <td>37</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.85</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.52</td>\n",
       "      <td>0.26</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>758</th>\n",
       "      <td>6</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.72</td>\n",
       "      <td>0.64</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.28</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.84</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>586</th>\n",
       "      <td>13</td>\n",
       "      <td>0.11</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.15</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.41</td>\n",
       "      <td>...</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.71</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>573</th>\n",
       "      <td>36</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.13</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.07</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.00</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>6</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.53</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.37</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.30</td>\n",
       "      <td>...</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>427</th>\n",
       "      <td>45</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.36</td>\n",
       "      <td>...</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.51</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.03</td>\n",
       "      <td>0.18</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows Ã— 98 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      state  population  householdsize  racepctblack  racePctWhite  \\\n",
       "1184     34        0.01           0.54          0.02          0.91   \n",
       "401      55        0.99           0.42          0.59          0.44   \n",
       "1864     34        0.01           0.53          0.02          0.95   \n",
       "1390     25        0.07           0.41          0.02          0.97   \n",
       "1066     37        0.05           0.41          0.11          0.85   \n",
       "758       6        0.02           0.71          0.17          0.41   \n",
       "586      13        0.11           0.52          1.00          0.15   \n",
       "573      36        0.03           0.66          0.13          0.73   \n",
       "56        6        0.16           0.44          0.05          0.76   \n",
       "427      45        0.03           0.35          0.67          0.47   \n",
       "\n",
       "      racePctAsian  racePctHisp  agePct12t21  agePct12t29  agePct16t24  ...  \\\n",
       "1184          0.27         0.04         0.37         0.41         0.25  ...   \n",
       "401           0.11         0.11         0.44         0.56         0.37  ...   \n",
       "1864          0.15         0.03         0.27         0.37         0.18  ...   \n",
       "1390          0.05         0.02         0.32         0.49         0.31  ...   \n",
       "1066          0.23         0.03         0.32         0.52         0.26  ...   \n",
       "758           0.72         0.64         0.41         0.45         0.28  ...   \n",
       "586           0.02         0.01         0.58         0.57         0.41  ...   \n",
       "573           0.61         0.07         1.00         1.00         1.00  ...   \n",
       "56            0.53         0.21         0.37         0.49         0.30  ...   \n",
       "427           0.02         0.01         0.45         0.48         0.36  ...   \n",
       "\n",
       "      NumInShelters  NumStreet  PctForeignBorn  PctBornSameState  \\\n",
       "1184           0.01       0.00            0.29              0.42   \n",
       "401            0.30       0.12            0.14              0.71   \n",
       "1864           0.01       0.00            0.17              0.54   \n",
       "1390           0.00       0.00            0.13              0.88   \n",
       "1066           0.00       0.00            0.17              0.33   \n",
       "758            0.00       0.00            0.82              0.45   \n",
       "586            0.02       0.00            0.02              0.80   \n",
       "573            0.01       0.00            0.34              0.48   \n",
       "56             0.03       0.01            0.42              0.49   \n",
       "427            0.01       0.01            0.02              0.80   \n",
       "\n",
       "      PctSameHouse85  PctSameCity85  PctSameState85  LandArea  PopDens  \\\n",
       "1184            0.72           0.74            0.62      0.01     0.20   \n",
       "401             0.52           0.79            0.75      0.28     0.55   \n",
       "1864            0.38           0.24            0.51      0.11     0.03   \n",
       "1390            0.76           0.74            0.84      0.05     0.27   \n",
       "1066            0.20           0.23            0.05      0.09     0.12   \n",
       "758             0.55           0.84            0.75      0.02     0.24   \n",
       "586             0.50           0.69            0.71      0.16     0.12   \n",
       "573             0.02           0.00            0.00      0.01     0.45   \n",
       "56              0.42           0.54            0.62      0.08     0.32   \n",
       "427             0.51           0.75            0.75      0.03     0.18   \n",
       "\n",
       "      PctUsePubTrans  \n",
       "1184            0.47  \n",
       "401             0.62  \n",
       "1864            0.09  \n",
       "1390            0.40  \n",
       "1066            0.01  \n",
       "758             0.18  \n",
       "586             0.10  \n",
       "573             0.34  \n",
       "56              0.56  \n",
       "427             0.05  \n",
       "\n",
       "[10 rows x 98 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1184    0.08\n",
       "401     0.40\n",
       "1864    0.02\n",
       "1390    0.18\n",
       "1066    0.07\n",
       "758     0.33\n",
       "586     0.56\n",
       "573     0.15\n",
       "56      0.22\n",
       "427     0.76\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_target_train[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1158    0.06\n",
       "1079    0.14\n",
       "1633    0.80\n",
       "1700    0.50\n",
       "1956    0.30\n",
       "1808    0.26\n",
       "136     0.09\n",
       "46      0.20\n",
       "1989    0.09\n",
       "4       0.03\n",
       "Name: ViolentCrimesPerPop, dtype: float64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_target_test[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.08, 0.4 , 0.02, 0.18, 0.07, 0.33, 0.56, ..., 0.22, 0.18, 0.16, 0.08, 0.19, 0.04, 1.  ])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge, ElasticNet, SGDRegressor\n",
    "import pylab as pl\n",
    "communities_train = np.array(communities_train)\n",
    "communities_target_train = communities_target_train.T\n",
    "communities_target_train = np.array(communities_target_train)\n",
    "communities_test = np.array(communities_test)\n",
    "communities_target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[34.  ,  0.01,  0.54,  0.02,  0.91,  0.27,  0.04, ...,  0.42,  0.72,  0.74,  0.62,  0.01,  0.2 ,  0.47],\n",
       "       [55.  ,  0.99,  0.42,  0.59,  0.44,  0.11,  0.11, ...,  0.71,  0.52,  0.79,  0.75,  0.28,  0.55,  0.62],\n",
       "       [34.  ,  0.01,  0.53,  0.02,  0.95,  0.15,  0.03, ...,  0.54,  0.38,  0.24,  0.51,  0.11,  0.03,  0.09],\n",
       "       [25.  ,  0.07,  0.41,  0.02,  0.97,  0.05,  0.02, ...,  0.88,  0.76,  0.74,  0.84,  0.05,  0.27,  0.4 ],\n",
       "       [37.  ,  0.05,  0.41,  0.11,  0.85,  0.23,  0.03, ...,  0.33,  0.2 ,  0.23,  0.05,  0.09,  0.12,  0.01],\n",
       "       [ 6.  ,  0.02,  0.71,  0.17,  0.41,  0.72,  0.64, ...,  0.45,  0.55,  0.84,  0.75,  0.02,  0.24,  0.18],\n",
       "       [13.  ,  0.11,  0.52,  1.  ,  0.15,  0.02,  0.01, ...,  0.8 ,  0.5 ,  0.69,  0.71,  0.16,  0.12,  0.1 ],\n",
       "       ...,\n",
       "       [53.  ,  0.  ,  0.34,  0.01,  0.95,  0.06,  0.06, ...,  0.59,  0.42,  0.56,  0.64,  0.01,  0.17,  0.05],\n",
       "       [34.  ,  0.04,  0.52,  0.02,  0.86,  0.29,  0.32, ...,  0.6 ,  0.71,  0.7 ,  0.72,  0.02,  0.32,  0.56],\n",
       "       [ 6.  ,  0.06,  0.43,  0.02,  0.57,  1.  ,  0.2 , ...,  0.39,  0.55,  0.73,  0.61,  0.03,  0.37,  0.1 ],\n",
       "       [18.  ,  0.05,  0.32,  0.04,  0.94,  0.06,  0.03, ...,  0.77,  0.51,  0.69,  0.7 ,  0.04,  0.27,  0.1 ],\n",
       "       [34.  ,  0.02,  0.48,  0.23,  0.76,  0.18,  0.06, ...,  0.53,  0.76,  0.65,  0.6 ,  0.01,  0.47,  0.98],\n",
       "       [53.  ,  0.01,  0.56,  0.09,  0.77,  0.52,  0.1 , ...,  0.16,  0.09,  0.  ,  0.  ,  0.02,  0.19,  0.01],\n",
       "       [11.  ,  0.96,  0.32,  1.  ,  0.  ,  0.11,  0.1 , ...,  0.36,  0.57,  0.61,  0.33,  0.18,  0.83,  1.  ]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.set_printoptions(precision=2, linewidth=120, suppress=True, edgeitems=7)\n",
    "communities_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([np.concatenate((v,[1])) for v in communities_train])\n",
    "y_target = communities_target_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standRegres(xArr,yArr):\n",
    "    Matrix_X = np.mat(xArr); Matrix_y = np.mat(yArr).T\n",
    "    xTx = Matrix_X.T*Matrix_X\n",
    "    if np.linalg.det(xTx) == 0.0:\n",
    "        print(\"This matrix is singular, cannot do inverse\")\n",
    "        return\n",
    "    ws = xTx.I * (Matrix_X.T*Matrix_y)\n",
    "    return ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "implementing closed form solution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.  ],\n",
       "        [-0.02],\n",
       "        [-0.02],\n",
       "        [ 0.22],\n",
       "        [-0.05]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out = standRegres(x_train,y_target)\n",
    "out[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[-0.03,  0.62, -0.07,  0.12,  0.07,  0.44,  0.71, ...,  0.24,  0.15,  0.19,  0.2 ,  0.06,  0.05,  0.84]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Matrix_X=np.mat(x_train)\n",
    "Matrix_y=np.mat(y_target)\n",
    "Cap_y = Matrix_X*out\n",
    "Cap_y=Cap_y.T\n",
    "Cap_y[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Computing RMSE value for training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.11 0.22 0.09 0.06 0.   0.11 0.15 ... 0.02 0.03 0.03 0.12 0.13 0.01 0.16]]\n"
     ]
    }
   ],
   "source": [
    "p = np.array(Cap_y)# p is the array of predicted values\n",
    "_error_ = abs(p-y_target)\n",
    "print(_error_[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on Training Data:  [[5.02]]\n"
     ]
    }
   ],
   "source": [
    "total_error = np.dot(_error_,_error_.T)\n",
    "Training_data_rmse = np.sqrt(total_error/len(p))\n",
    "print(\"RMSE on Training Data: \", Training_data_rmse)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting correlation between predicted and actual values of ViolentCrimesPerPop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "pl.plot(p.T, y_target,'bo', markersize=2.5)\n",
    "pl.plot([0,1.2],[0,1.2], 'g-')\n",
    "pl.xlabel('Predicted')\n",
    "pl.ylabel('Actual')\n",
    "pl.show()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Correlation strong positive linear, with few outliers at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "L_reg = LinearRegression()\n",
    "def Cross_val(model, X_stat, y, n, verbose=False):\n",
    "    # model: regression model to be trained\n",
    "    # X_stat: the data matrix\n",
    "    # y: the target variable array\n",
    "    # n: the number of fold for x-validation\n",
    "    # Returns mean RMSE across all folds\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n, random_state=22)\n",
    "    xval_error_ = 0\n",
    "    f = 1\n",
    "    for train,test in kf.split(x_train):\n",
    "        model.fit(X_stat[train],y[train])\n",
    "        p = model.predict(x_train[test])\n",
    "        e = p-y_target[test]\n",
    "        rmse = np.sqrt(np.dot(e,e)/len(x_train[test]))\n",
    "        if verbose:\n",
    "            print(\"Fold %2d RMSE: %.4f\" % (f, rmse))\n",
    "        xval_error_ += rmse\n",
    "        f += 1\n",
    "    return xval_error_/n\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 RMSE: 0.1421\n",
      "Fold  2 RMSE: 0.1380\n",
      "Fold  3 RMSE: 0.1343\n",
      "Fold  4 RMSE: 0.1353\n",
      "Fold  5 RMSE: 0.1339\n",
      "Fold  6 RMSE: 0.1318\n",
      "Fold  7 RMSE: 0.1205\n",
      "Fold  8 RMSE: 0.1208\n",
      "Fold  9 RMSE: 0.1372\n",
      "Fold 10 RMSE: 0.1452\n"
     ]
    }
   ],
   "source": [
    "Cross_val_rmse = Cross_val(L_reg, x_train, y_target, 10, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Printing the 10-fold validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Method: Simple Linear Regression\n",
      "RMSE on training: 5.0178\n",
      "RMSE on 10-fold CV: 0.1339\n"
     ]
    }
   ],
   "source": [
    "# Comparing cross validation RMSE to training RMSE\n",
    "Method = 'Simple Linear Regression'\n",
    "print('Method: %s' %Method)\n",
    "print('RMSE on training: %.4f' %Training_data_rmse)\n",
    "print('RMSE on 10-fold CV: %.4f' %Cross_val_rmse)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "FEATURE SELECTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import feature_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "fea_sel = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=30)\n",
    "X_stat_train_fs = fea_sel.fit_transform(communities_train, communities_target_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of most informative variables and their weights are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  3,  4, 11, 13, 16, 18, 20, 28, 29, 30, 31, 33, 37, 39, 40, 42, 43, 44, 45, 48, 49, 66, 67, 68, 70, 72, 73,\n",
       "       76, 88], dtype=int64)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "communities_train2 = pd.DataFrame(communities_train)\n",
    "colname=np.array(communities_train2.columns[fea_sel.get_support()].values)\n",
    "colname"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         1  256.03\n",
      "         3  1074.89\n",
      "         4  1412.51\n",
      "        11  247.78\n",
      "        13  341.63\n",
      "        16  756.01\n",
      "        18  784.57\n",
      "        20  366.90\n",
      "        28  400.31\n",
      "        29  578.82\n",
      "        30  319.22\n",
      "        31  472.20\n",
      "        33  533.91\n",
      "        37  602.77\n",
      "        39  704.77\n",
      "        40  693.14\n",
      "        42  1657.87\n",
      "        43  1972.80\n",
      "        44  1342.17\n",
      "        45  1299.54\n",
      "        48  431.64\n",
      "        49  1936.12\n",
      "        66  630.76\n",
      "        67  375.65\n",
      "        68  487.96\n",
      "        70  339.97\n",
      "        72  478.53\n",
      "        73  507.64\n",
      "        76  505.86\n",
      "        88  265.85\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(communities_train2.columns.values)):\n",
    "    if fea_sel.get_support()[i]:\n",
    "        print(\"%10s  %3.2f\" % (communities_train2.columns[i], fea_sel.scores_[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The feature selection displayed the column numbers. The names of columns associated with the column numbers displayed are:\n",
    "\n",
    "['population','racepctblack','racePctWhite','numbUrban','medIncome','pctWInvInc','pctWPubAsst','medFamInc','NumUnderPov','PctPopUnderPov','PctLess9thGrade','PctNotHSGrad','PctUnemployed','MalePctDivorce','FemalePctDiv','TotalPctDiv','PctFam2Par','PctKids2Par','PctYoungKids2Par','PctTeen2Par','NumIlleg','PctIlleg','PctPersOwnOccup','PctPersDenseHous','PctHousLess3BR','HousVacant','PctHousOwnOcc','PctVacantBoarded','PctHousNoPhone','NumInShelters']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting best percentile\n",
    "p = range(1, 100, 5)\n",
    "optimal_p = np.where(communities_train2 == communities_train2.min())[0][0]\n",
    "optimal_fea = p[optimal_p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_selection = feature_selection.SelectPercentile(feature_selection.f_regression, percentile=optimal_fea)\n",
    "communities_train_fs = feat_selection.fit_transform(communities_train, communities_target_train)\n",
    "communities_train_fs = np.array([np.concatenate((v, [1])) for v in communities_train_fs])\n",
    "\n",
    "final_model = LinearRegression()\n",
    "L_reg.fit(communities_train_fs, communities_target_train)\n",
    "\n",
    "communities_test_fs = feat_selection.transform(communities_test)\n",
    "communities_test_fs = np.array([np.concatenate((v, [1])) for v in communities_test_fs])\n",
    "com_pred = L_reg.predict(communities_test_fs)\n",
    "\n",
    "error = com_pred - communities_target_test\n",
    "total_error = np.dot(error, error)\n",
    "test_data_rmse = np.sqrt(total_error/len(com_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RMSE on training data:  0.16697902614129903\n"
     ]
    }
   ],
   "source": [
    "print(\"RMSE on training data: \",test_data_rmse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error:  1158   -0.097363\n",
      "1079    0.130001\n",
      "1633   -0.222635\n",
      "1700   -0.155235\n",
      "1956    0.069686\n",
      "1808    0.176143\n",
      "136    -0.085827\n",
      "46     -0.013071\n",
      "1989    0.096929\n",
      "4      -0.034135\n",
      "246    -0.355235\n",
      "485     0.086458\n",
      "1254   -0.007835\n",
      "559     0.050472\n",
      "142     0.227522\n",
      "492    -0.145670\n",
      "992    -0.113542\n",
      "634     0.281536\n",
      "1460   -0.001063\n",
      "206    -0.114606\n",
      "962     0.127087\n",
      "960     0.117994\n",
      "874     0.027994\n",
      "1869    0.021851\n",
      "306     0.040001\n",
      "1133   -0.004292\n",
      "1506   -0.055707\n",
      "1678    0.320279\n",
      "126    -0.057835\n",
      "1876    0.006929\n",
      "          ...   \n",
      "1588    0.180158\n",
      "1243    0.057244\n",
      "912    -0.042756\n",
      "473    -0.082006\n",
      "29      0.042322\n",
      "1299    0.251065\n",
      "1421   -0.346928\n",
      "1206    0.042008\n",
      "1326   -0.518464\n",
      "72      0.070472\n",
      "393    -0.260156\n",
      "1102   -0.282599\n",
      "177    -0.269250\n",
      "9      -0.004606\n",
      "1273   -0.347871\n",
      "1538   -0.006928\n",
      "649     0.143701\n",
      "322     0.191694\n",
      "368     0.047087\n",
      "294     0.053701\n",
      "1048   -0.029213\n",
      "1776   -0.034135\n",
      "1886   -0.111378\n",
      "482    -0.220628\n",
      "156    -0.009213\n",
      "830     0.090315\n",
      "782     0.253072\n",
      "596     0.136615\n",
      "372     0.098780\n",
      "591    -0.118185\n",
      "Name: ViolentCrimesPerPop, Length: 399, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(\"Error: \", error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Error:  11.124916073267553\n"
     ]
    }
   ],
   "source": [
    "print(\"Total Error: \", total_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1d) Ridge Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "def calc_params(X_stat, y, clf, param_values, param_name, K):\n",
    "    \n",
    "    # Convert input to Numpy arrays\n",
    "    X_stat = np.array(X_stat)\n",
    "    y = np.array(y)\n",
    "\n",
    "    # initialize training and testing score arrays with zeros\n",
    "    train_scores = np.zeros(len(param_values))\n",
    "    test_scores = np.zeros(len(param_values))\n",
    "    \n",
    "    # iterate over the different parameter values\n",
    "    for i, param_value in enumerate(param_values):\n",
    "        print(param_name, ' = ', param_value)\n",
    "        \n",
    "        # set classifier parameters\n",
    "        clf.set_params(**{param_name:param_value})\n",
    "        \n",
    "        # initialize the K scores obtained for each fold\n",
    "        k_train_scores = np.zeros(K)\n",
    "        k_test_scores = np.zeros(K)\n",
    "        \n",
    "        # create KFold cross validation\n",
    "        cv = KFold(n_splits=K, shuffle=True, random_state=0)\n",
    "        \n",
    "        # iterate over the K folds\n",
    "        j = 0\n",
    "        for train, test in cv.split(X_stat):\n",
    "            # fit the classifier in the corresponding fold\n",
    "            # and obtain the corresponding accuracy scores on train and test sets\n",
    "            clf.fit(X_stat[train], y[train])\n",
    "            k_train_scores[j] = clf.score(X_stat[train], y[train])\n",
    "            k_test_scores[j] = clf.score(X_stat[test], y[test])\n",
    "            j += 1\n",
    "            \n",
    "        # store the mean of the K fold scores\n",
    "        train_scores[i] = np.mean(k_train_scores)\n",
    "        test_scores[i] = np.mean(k_test_scores)\n",
    "       \n",
    "    # plot the training and testing scores in a log scale\n",
    "    plt.plot(param_values, train_scores, label='Train', alpha=0.4, lw=2, c='b')\n",
    "    plt.plot(param_values, test_scores, label='X_stat-Val', alpha=0.4, lw=2, c='g')\n",
    "    plt.legend(loc=7)\n",
    "    plt.xlabel(param_name + \" values\")\n",
    "    plt.ylabel(\"Mean cross validation accuracy\")\n",
    "\n",
    "    # return the training and testing scores on each parameter value\n",
    "    return train_scores, test_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0  1  3  4  6  7  9 11 12 14 15 17 18 20 22 23 25 26 28 30]\n"
     ]
    }
   ],
   "source": [
    "alpha_values = np.linspace(0, 30.0, 20, dtype=int)\n",
    "print(alpha_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha  =  0\n",
      "alpha  =  1\n",
      "alpha  =  3\n",
      "alpha  =  4\n",
      "alpha  =  6\n",
      "alpha  =  7\n",
      "alpha  =  9\n",
      "alpha  =  11\n",
      "alpha  =  12\n",
      "alpha  =  14\n",
      "alpha  =  15\n",
      "alpha  =  17\n",
      "alpha  =  18\n",
      "alpha  =  20\n",
      "alpha  =  22\n",
      "alpha  =  23\n",
      "alpha  =  25\n",
      "alpha  =  26\n",
      "alpha  =  28\n",
      "alpha  =  30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "ridge_regression = Ridge()\n",
    "train_data_scores, test_data_scores = calc_params(communities_train, communities_target_train, ridge_regression, alpha_values, 'alpha', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "best alpha value is 1.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71 0.7  0.69 0.69 0.69 0.69 0.69 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.68 0.67 0.67] [0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66 0.66]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_scores, test_data_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Cross_val(model, X_stat, y, n, verbose=False):\n",
    "    # model: regression model to be trained\n",
    "    # X_stat: the data matrix\n",
    "    # y: the target variable array\n",
    "    # n: the number of fold for x-validation\n",
    "    # Returns mean RMSE across all folds\n",
    "    \n",
    "    from sklearn.model_selection import KFold\n",
    "    kf = KFold(n_splits=n, random_state=22)\n",
    "    xval_error_ = 0\n",
    "    f = 1\n",
    "    for train,test in kf.split(x_train):\n",
    "        model.fit(X_stat[train],y[train])\n",
    "        p = model.predict(x_train[test])\n",
    "        e = p-y[test]\n",
    "        rmse = np.sqrt(np.dot(e,e)/len(x_train[test]))\n",
    "        if verbose:\n",
    "            print(\"Fold %2d RMSE: %.4f\" % (f, rmse))\n",
    "        xval_error_ += rmse\n",
    "        f += 1\n",
    "    return xval_error_/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Ridge(alpha=1.5, copy_X=True, fit_intercept=True, max_iter=None,\n",
       "   normalize=False, random_state=None, solver='auto', tol=0.001)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ridge_regression = Ridge(alpha=1.5)\n",
    "# Train the model using the training set\n",
    "ridge_regression.fit(x_train,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 RMSE: 0.1367\n",
      "Fold  2 RMSE: 0.1348\n",
      "Fold  3 RMSE: 0.1325\n",
      "Fold  4 RMSE: 0.1197\n",
      "Fold  5 RMSE: 0.1399\n",
      "\n",
      "\n",
      "Method: Ridge Regression\n",
      "RMSE on training: 0.1272\n",
      "RMSE on 10-fold Cross Validation: 0.1327\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "p = ridge_regression.predict(x_train)\n",
    "_error_ = p-y_target\n",
    "total_error = np.dot(_error_,_error_)\n",
    "training_data_rmse = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "\n",
    "rmse_10fold = Cross_val(ridge_regression, x_train, y_target, 5, verbose=True)\n",
    "\n",
    "method = 'Ridge Regression'\n",
    "print(\"\\n\")\n",
    "print('Method: %s' %method)\n",
    "print('RMSE on training: %.4f' %training_data_rmse)\n",
    "print('RMSE on 10-fold Cross Validation: %.4f' %rmse_10fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lasso regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha  =  0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:32: UserWarning: With alpha=0, this algorithm does not converge well. You are advised to use the LinearRegression estimator\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:478: UserWarning: Coordinate descent with no regularization may lead to unexpected results and is discouraged.\n",
      "  positive)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\coordinate_descent.py:492: ConvergenceWarning: Objective did not converge. You might want to increase the number of iterations. Fitting data with very small alpha may cause precision problems.\n",
      "  ConvergenceWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "alpha  =  1\n",
      "alpha  =  3\n",
      "alpha  =  4\n",
      "alpha  =  6\n",
      "alpha  =  7\n",
      "alpha  =  9\n",
      "alpha  =  11\n",
      "alpha  =  12\n",
      "alpha  =  14\n",
      "alpha  =  15\n",
      "alpha  =  17\n",
      "alpha  =  18\n",
      "alpha  =  20\n",
      "alpha  =  22\n",
      "alpha  =  23\n",
      "alpha  =  25\n",
      "alpha  =  26\n",
      "alpha  =  28\n",
      "alpha  =  30\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "Lasso_regression = Lasso()\n",
    "train_data_scores, test_data_scores = calc_params(communities_train, communities_target_train, Lasso_regression, alpha_values, 'alpha', 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From Lasso regression best alpha value is 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.71 0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.   0.  ] [ 0.66 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01 -0.01\n",
      " -0.01]\n"
     ]
    }
   ],
   "source": [
    "print(train_data_scores, test_data_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lasso(alpha=2, copy_X=True, fit_intercept=True, max_iter=1000,\n",
       "   normalize=False, positive=False, precompute=False, random_state=None,\n",
       "   selection='cyclic', tol=0.0001, warm_start=False)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lasso_regression = Lasso(alpha=2)\n",
    "# Train the model using the training set\n",
    "lasso_regression.fit(x_train,y_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 RMSE: 0.2307\n",
      "Fold  2 RMSE: 0.2168\n",
      "Fold  3 RMSE: 0.2439\n",
      "Fold  4 RMSE: 0.2184\n",
      "Fold  5 RMSE: 0.2452\n",
      "\n",
      "\n",
      "Method: Lasso Regression\n",
      "RMSE on training: 0.2312\n",
      "RMSE on 10-fold Cross Validation: 0.2310\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "p = lasso_regression.predict(x_train)\n",
    "_error_ = p-y_target\n",
    "total_error = np.dot(_error_,_error_)\n",
    "training_data_rmse = np.sqrt(total_error/len(p))\n",
    "\n",
    "# Compute RMSE using 10-fold x-validation\n",
    "\n",
    "rmse_10fold = Cross_val(lasso_regression, x_train, y_target, 5, verbose=True)\n",
    "\n",
    "method = 'Lasso Regression'\n",
    "print(\"\\n\")\n",
    "print('Method: %s' %method)\n",
    "print('RMSE on training: %.4f' %training_data_rmse)\n",
    "print('RMSE on 10-fold Cross Validation: %.4f' %rmse_10fold)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Value of RMSE is improved in lasso regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Q: 1)e Stochastic Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StandardScaler(copy=True, with_mean=True, with_std=True)"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_scaler = StandardScaler()\n",
    "data_scaler.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_reg_scale = data_scaler.transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_regression = SGDRegressor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_param = {\"penalty\": ['l1', 'l2'],\n",
    "              \"alpha\": np.linspace(0.0001, 20)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_split.py:2053: FutureWarning: You should specify a value for 'cv' instead of relying on the default value. The default value will change from 3 to 5 in version 0.22.\n",
      "  warnings.warn(CV_WARNING, FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GridSearchCV(cv='warn', error_score='raise-deprecating',\n",
      "       estimator=SGDRegressor(alpha=0.0001, average=False, early_stopping=False, epsilon=0.1,\n",
      "       eta0=0.01, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='invscaling', loss='squared_loss', max_iter=None,\n",
      "       n_iter=None, n_iter_no_change=5, penalty='l2', power_t=0.25,\n",
      "       random_state=None, shuffle=True, tol=None, validation_fraction=0.1,\n",
      "       verbose=0, warm_start=False),\n",
      "       fit_params=None, iid='warn', n_jobs=None,\n",
      "       param_grid={'penalty': ['l1', 'l2'], 'alpha': array([ 0.0001 ,  0.40826,  0.81642,  1.22458,  1.63274,  2.04091,  2.44907,  2.85723,  3.26539,  3.67355,  4.08171,\n",
      "        4.48987,  4.89803,  5.3062 ,  5.71436,  6.12252,  6.53068,  6.93884,  7.347  ,  7.75516,  8.16332,  8.57149,\n",
      "        8.97965,  9...., 16.73471, 17.14287, 17.55103,\n",
      "       17.95919, 18.36736, 18.77552, 19.18368, 19.59184, 20.     ])},\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring=None, verbose=0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:841: DeprecationWarning: The default of the `iid` parameter will change from True to False in version 0.22 and will be removed in 0.24. This will change numeric results when test-set sizes are unequal.\n",
      "  DeprecationWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "SG_grid = GridSearchCV(estimator=SG_regression,param_grid = SG_param)\n",
    "SG_grid.fit(communities_train,communities_target_train)\n",
    "print(SG_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "best alpha value is:  8.163324489795919\n"
     ]
    }
   ],
   "source": [
    "print(\"best alpha value is: \", SG_grid.best_estimator_.alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best penalty between l1 and l2 is:  l1\n"
     ]
    }
   ],
   "source": [
    "print(\"Best penalty between l1 and l2 is: \", SG_grid.best_estimator_.get_params()['penalty'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_model = SGDRegressor(penalty='l2', alpha=5.714, max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold  1 RMSE: 0.1385\n",
      "Fold  2 RMSE: 0.1395\n",
      "Fold  3 RMSE: 0.1385\n",
      "Fold  4 RMSE: 0.1405\n",
      "Fold  5 RMSE: 0.1422\n",
      "Fold  6 RMSE: 0.1407\n",
      "Fold  7 RMSE: 0.1216\n",
      "Fold  8 RMSE: 0.1276\n",
      "Fold  9 RMSE: 0.1434\n",
      "Fold 10 RMSE: 0.1453\n",
      "Method: Stochastic Gradient Descent Regression\n",
      "RMSE on training: 0.1336\n",
      "RMSE on 10-fold CV: 0.1378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "# Compute RMSE on training data\n",
    "from sklearn.model_selection import KFold\n",
    "SG_regression.fit(SG_reg_scale,y_target)\n",
    "p = SG_regression.predict(SG_reg_scale)\n",
    "_error_ = p-y_target\n",
    "total_error = np.dot(_error_,_error_)\n",
    "rmse_train = np.sqrt(total_error/len(p))\n",
    "n = 10\n",
    "kf = KFold(n_splits=n, random_state=22)\n",
    "xval_error_ = 0\n",
    "f = 1\n",
    "\n",
    "for train,test in kf.split(x_train):\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(x_train[train])  # Don't cheat - fit only on training data\n",
    "    xtrain_s = scaler.transform(x_train[train])\n",
    "    xtest_s = scaler.transform(x_train[test])  # apply same transformation to test data\n",
    "    SG_regression.fit(xtrain_s,y_target[train])\n",
    "    p = SG_regression.predict(xtest_s)\n",
    "    e = p-y_target[test]\n",
    "    \n",
    "    rmse = np.sqrt(np.dot(e,e)/len(x_train[test]))\n",
    "    print(\"Fold %2d RMSE: %.4f\" % (f, rmse))\n",
    "    xval_error_ += rmse\n",
    "    f += 1\n",
    "\n",
    "rmse_10cv = xval_error_/n\n",
    "\n",
    "method = 'Stochastic Gradient Descent Regression'\n",
    "print('Method: %s' %method)\n",
    "print('RMSE on training: %.4f' %rmse_train)\n",
    "print('RMSE on 10-fold CV: %.4f' %rmse_10cv)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Creating SG model with \"Elasticnet\" as penality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "SG_2 = SGDRegressor(penalty='elasticnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_values = np.linspace(0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.0\n",
      "l1_ratio  =  0.02040816326530612\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.04081632653061224\n",
      "l1_ratio  =  0.061224489795918366\n",
      "l1_ratio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  =  0.08163265306122448\n",
      "l1_ratio  =  0.1020408163265306\n",
      "l1_ratio  =  0.12244897959183673\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.14285714285714285\n",
      "l1_ratio  =  0.16326530612244897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.18367346938775508\n",
      "l1_ratio  =  0.2040816326530612\n",
      "l1_ratio  =  0.22448979591836732\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.24489795918367346\n",
      "l1_ratio  =  0.26530612244897955\n",
      "l1_ratio  =  0.2857142857142857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.3061224489795918\n",
      "l1_ratio  =  0.32653061224489793\n",
      "l1_ratio  =  0.3469387755102041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.36734693877551017\n",
      "l1_ratio  =  0.3877551020408163\n",
      "l1_ratio  =  0.4081632653061224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.42857142857142855\n",
      "l1_ratio  =  0.44897959183673464\n",
      "l1_ratio"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  =  0.4693877551020408\n",
      "l1_ratio  =  0.4897959183673469\n",
      "l1_ratio  =  0.5102040816326531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.5306122448979591\n",
      "l1_ratio  =  0.5510204081632653\n",
      "l1_ratio  =  0.5714285714285714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.5918367346938775\n",
      "l1_ratio  =  0.6122448979591836\n",
      "l1_ratio  =  0.6326530612244897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.6530612244897959\n",
      "l1_ratio  =  0.673469387755102\n",
      "l1_ratio  =  0.6938775510204082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.7142857142857142\n",
      "l1_ratio  =  0.7346938775510203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.7551020408163265\n",
      "l1_ratio  =  0.7755102040816326\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.7959183673469387\n",
      "l1_ratio  =  0.8163265306122448\n",
      "l1_ratio  =  0.836734693877551\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.8571428571428571\n",
      "l1_ratio  =  0.8775510204081632\n",
      "l1_ratio  =  0.8979591836734693\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.9183673469387754\n",
      "l1_ratio  =  0.9387755102040816\n",
      "l1_ratio  =  0.9591836734693877\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1_ratio  =  0.9795918367346939\n",
      "l1_ratio  =  1.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n",
      "C:\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\stochastic_gradient.py:166: FutureWarning: max_iter and tol parameters have been added in SGDRegressor in 0.19. If both are left unset, they default to max_iter=5 and tol=None. If tol is not None, max_iter defaults to max_iter=1000. From 0.21, default max_iter will be 1000, and default tol will be 1e-3.\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "SG_train_values, SG_test_values = calc_params(communities_train, communities_target_train, SG_2, parameter_values, 'l1_ratio', 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
